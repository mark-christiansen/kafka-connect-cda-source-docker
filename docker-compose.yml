version: '3.5'
services:

  ################## KAFKA ##################

  zoo1:
    image: confluentinc/cp-zookeeper:${CONFLUENT_VERSION}
    hostname: zoo1.${DOMAIN}
    container_name: zoo1
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_SERVERS: zoo1.${DOMAIN}:2888:3888
      ZOOKEEPER_LOG4J_ROOT_LOGLEVEL: DEBUG
      KAFKA_OPTS: "-Dzookeeper.4lw.commands.whitelist=*"
      KAFKA_HEAP_OPTS: "-Xms${ZK_HEAP} -Xmx${ZK_HEAP}"
    volumes:
      - ./volumes/zoo-1/data:/var/lib/zookeeper/data
    networks:
      - kafka-network
    healthcheck:
      test: ["CMD", "bash", "-c", "(echo ruok | nc zoo1.${DOMAIN} 2181) | grep -e imok"]
      start_period: 5s
      interval: 20s
      timeout: 10s
      retries: 20

  kafka1:
    image: confluentinc/cp-server:${CONFLUENT_VERSION}
    hostname: kafka1.${DOMAIN}
    container_name: kafka1
    ulimits:
      nofile:
        soft: 82920
        hard: 82920
    links:
      - zoo1
    depends_on:
      zoo1:
        condition: service_healthy
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      KAFKA_BROKER_ID: 1
      # zookeeper
      KAFKA_ZOOKEEPER_CONNECT: zoo1.${DOMAIN}:2181
      KAFKA_ZOOKEEPER_CLIENT_CNXN_SOCKET: org.apache.zookeeper.ClientCnxnSocketNetty
      # listeners
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka1.${DOMAIN}:29092,EXTERNAL://localhost:9092
      KAFKA_LISTENERS: INTERNAL://kafka1.${DOMAIN}:29092,EXTERNAL://kafka1.${DOMAIN}:9092
      KAFKA_SECURITY_PROTOCOL: PLAINTEXT
      KAFKA_CONFLUENT_BALANCER_ENABLE: 'true'
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_CONFLUENT_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_CONFLUENT_LICENSE_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_CONFLUENT_BALANCER_TOPIC_REPLICATION_FACTOR: 1
      # metrics reporter
      KAFKA_METRIC_REPORTERS: io.confluent.metrics.reporter.ConfluentMetricsReporter
      CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: 1
      CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: kafka1:29092
      CONFLUENT_METRICS_REPORTER_SECURITY_PROTOCOL: PLAINTEXT
      # cluster linking
      CONFLUENT_CLUSTER_LINK_METADATA_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_PASSWORD_ENCODER_SECRET: cl-secret
      # logging
      KAFKA_LOG4J_ROOT_LOGLEVEL: INFO
      KAFKA_LOG4J_LOGGERS: kafka.authorizer.logger=INFO
      #KAFKA_OPTS: '-Djavax.net.debug=ssl'
      #KAFKA_JMX_PORT: 9010
      #KAFKA_JMX_HOSTNAME: localhost
      KAFKA_HEAP_OPTS: "-Xms${BROKER_HEAP} -Xmx${BROKER_HEAP}"
    volumes:
      - ./volumes/kafka-1/data:/var/lib/kafka/data
    networks:
      - kafka-network
    healthcheck:
      test: ["CMD", "bash", "-c", "kafka-cluster cluster-id --bootstrap-server kafka1.${DOMAIN}:29092 | grep -e 'Cluster ID: .*'"]
      start_period: 30s
      interval: 10s
      timeout: 10s
      retries: 10

  schema1:
    image: confluentinc/cp-schema-registry:${CONFLUENT_VERSION}
    hostname: schema1.${DOMAIN}
    container_name: schema1
    links:
      - kafka1
    depends_on:
      kafka1:
        condition: service_healthy
    ports:
      - "8081:8081"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: 'schema1'
      SCHEMA_REGISTRY_LISTENERS: 'http://0.0.0.0:8081'
      # kafka store
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: 'PLAINTEXT://kafka1.${DOMAIN}:29092'
      SCHEMA_REGISTRY_KAFKASTORE_SECURITY_PROTOCOL: 'PLAINTEXT'
      SCHEMA_REGISTRY_KAFKASTORE_TOPIC: '_schemas'
      SCHEMA_REGISTRY_KAFKASTORE_ZK_SESSION_TIMEOUT_MS: 60000
      SCHEMA_REGISTRY_KAFKASTORE_TIMEOUT_MS: 10000
      SCHEMA_REGISTRY_KAFKASTORE_INIT_TIMEOUT_MS: 120000
      # other
      SCHEMA_REGISTRY_INTER_INSTANCE_PROTOCOL: 'http'
      SCHEMA_REGISTRY_SCHEMA_REGISTRY_GROUP_ID: 'schema-registry'
      SCHEMA_REGISTRY_LEADER_ELIGIBILITY: 'true'
      SCHEMA_REGISTRY_MODE_MUTABILITY: 'true'
      SCHEMA_REGISTRY_DEBUG: 'true'
      KAFKA_HEAP_OPTS: "-Xms${SCHEMA_HEAP} -Xmx${SCHEMA_HEAP}"
    networks:
      - kafka-network
    healthcheck:
      test: ["CMD", "bash", "-c", "curl http://schema1.${DOMAIN}:8081/subjects"]
      interval: 10s
      timeout: 10s
      retries: 20

  ################## CONNECT ##################

  cda1:
    image: ${CDA_CONNECT_IMAGE}
    hostname: cda1
    container_name: cda1
    links:
      - schema1
    depends_on:
      schema1:
        condition: service_healthy
    ports:
      - "8083:8083"
      - "9010:9010"
      - "9011:9011"
    environment:
      CONNECT_BOOTSTRAP_SERVERS: 'PLAINTEXT://kafka1.${DOMAIN}:29092'
      CONNECT_SECURITY_PROTOCOL: 'PLAINTEXT'
      CONNECT_REST_ADVERTISED_HOST_NAME: cda1
      CONNECT_REST_PORT: 8083
      CONNECT_GROUP_ID: cda-connect-cluster
      CONNECT_CONFIG_STORAGE_TOPIC: cda-connect-configs
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_FLUSH_INTERVAL_MS: 10000
      CONNECT_OFFSET_STORAGE_TOPIC: cda-connect-offsets
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_TOPIC: cda-connect-status
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_KEY_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: http://schema1.${DOMAIN}:8081
      CONNECT_KEY_SUBJECT_NAME_STRATEGY: io.confluent.kafka.serializers.subject.RecordNameStrategy
      CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema1.${DOMAIN}:8081
      CONNECT_VALUE_SUBJECT_NAME_STRATEGY: io.confluent.kafka.serializers.subject.RecordNameStrategy
      CONNECT_INTERNAL_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_INTERNAL_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_ZOOKEEPER_CONNECT: zoo1.${DOMAIN}:2181
      CONNECT_CONNECTOR_CLIENT_CONFIG_OVERRIDE_POLICY: All
      CONNECT_LISTENERS: http://0.0.0.0:8083
      CONNECT_REST_ADVERTISED_LISTENER: http
      # Set in seconds, this was changed to allow for detection of new topics and partitions quicker by the
      # JDBC sink connector (default is five minutes). Comment out this setting for overall better consumer
      # performance.
      CONNECT_METADATA_MAX_AGE_MS: 60
      CONNECT_PLUGIN_PATH: /usr/share/java,/usr/share/confluent-hub-components
      CONNECT_LOG4J_LOGGERS: org.apache.zookeeper=ERROR,org.I0Itec.zkclient=ERROR,org.reflections=ERROR,org.apache.kafka=ERROR,org.apache.hadoop=ERROR,org.apache.parquet=ERROR,io.confluent=ERROR,org.apache.kafka.connect.runtime=ERROR
      KAFKA_OPTS: >-
        -Dcom.sun.management.jmxremote 
        -Dcom.sun.management.jmxremote.authenticate=false 
        -Dcom.sun.management.jmxremote.local.only=false 
        -Dcom.sun.management.jmxremote.port=9010
        -Dcom.sun.management.jmxremote.rmi.port=9010
        -Dcom.sun.management.jmxremote.ssl=false
        -Djava.rmi.server.hostname=localhost
        -javaagent:/usr/share/jmx-exporter/jmx_prometheus_javaagent-0.16.1.jar=9011:/usr/share/jmx-exporter/kafka_connect.yml
      KAFKA_JVM_PERFORMANCE_OPTS: >-
        -server -XX:+UseG1GC -XX:GCTimeRatio=1
        -XX:MinHeapFreeRatio=10 -XX:MaxHeapFreeRatio=20
        -XX:MaxGCPauseMillis=10000 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent
        -XX:MaxInlineLevel=15 -Djava.awt.headless=true
      KAFKA_HEAP_OPTS: "-Xms${CONNECT_HEAP} -Xmx${CONNECT_HEAP}"
    volumes:
      - ./volumes/s3:/s3
      - ./jmx-exporter:/usr/share/jmx-exporter
    networks:
      - kafka-network
    healthcheck:
      test: ["CMD", "bash", "-c", "curl http://cda1.${DOMAIN}:8083/connectors"]
      start_period: 30s
      interval: 10s
      timeout: 10s
      retries: 10

  ################## DATABASE ##################

#  postgres:
#    image: postgres:latest
#    hostname: postgres
#    container_name: postgres
#    ports:
#      - "5432:5432"
#    volumes:
#      - ./volumes/postgres/data:/var/lib/postgresql/data
#    environment:
#      POSTGRES_DB: cda
#      POSTGRES_USER: kafka-connect-user
#      POSTGRES_PASSWORD: K@fk@Conn3ct!
#    networks:
#      - kafka-network

  ################## MONIORING ##################

  prometheus:
    image: ubuntu/prometheus
    hostname: prometheus
    container_name: prometheus
    ports:
      - "9090:9090/tcp"
    environment:
      DOMAIN: ${DOMAIN}
    volumes:
      - ./volumes/prometheus:/prometheus
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
    networks:
      - kafka-network

  grafana:
    image: grafana/grafana
    hostname: grafana
    container_name: grafana
    depends_on:
      - prometheus
    ports:
      - "3000:3000"
    environment:
      DOMAIN: ${DOMAIN}
      # Disable login for Grafana
      GF_AUTH_DISABLE_LOGIN_FORM: 'true'
      GF_AUTH_ANONYMOUS_ENABLED: 'true'
      GF_AUTH_ANONYMOUS_ORG_ROLE: 'Admin'
      GF_USERS_ALLOW_SIGN_UP: 'false'
    volumes:
      - ./volumes/grafana/data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning
      - ./grafana/grafana.ini:/etc/grafana/grafana.ini
      - ./grafana/dashboards:/etc/grafana/dashboards
    networks:
      - kafka-network

networks:
  kafka-network:
    name: ${DOMAIN}